{
    "id": "stabilityai/stable-diffusion-xl-base-1.0",
    "sha": "462165984030d82259a11f4367a4eed129e94a7b",
    "pipeline_tag": "text-to-image",
    "library_name": "diffusers",
    "private": false,
    "gated": false,
    "siblings": [
        {
            "rfilename": ".gitattributes",
            "size": 1562
        },
        {
            "rfilename": "01.png",
            "size": 4608613
        },
        {
            "rfilename": "LICENSE.md",
            "size": 14109
        },
        {
            "rfilename": "README.md",
            "size": 8668
        },
        {
            "rfilename": "comparison.png",
            "size": 130252
        },
        {
            "rfilename": "model_index.json",
            "size": 609
        },
        {
            "rfilename": "pipeline.png",
            "size": 80188
        },
        {
            "rfilename": "scheduler/scheduler_config.json",
            "size": 479
        },
        {
            "rfilename": "sd_xl_base_1.0.safetensors",
            "size": 6938078334
        },
        {
            "rfilename": "sd_xl_base_1.0_0.9vae.safetensors",
            "size": 6938078334
        },
        {
            "rfilename": "sd_xl_offset_example-lora_1.0.safetensors",
            "size": 49553604
        },
        {
            "rfilename": "text_encoder/config.json",
            "size": 565
        },
        {
            "rfilename": "text_encoder/flax_model.msgpack",
            "size": 492248682
        },
        {
            "rfilename": "text_encoder/model.fp16.safetensors",
            "size": 246144152
        },
        {
            "rfilename": "text_encoder/model.onnx",
            "size": 492587457
        },
        {
            "rfilename": "text_encoder/model.safetensors",
            "size": 492265168
        },
        {
            "rfilename": "text_encoder/openvino_model.bin",
            "size": 492242672
        },
        {
            "rfilename": "text_encoder/openvino_model.xml",
            "size": 1057789
        },
        {
            "rfilename": "text_encoder_2/config.json",
            "size": 575
        },
        {
            "rfilename": "text_encoder_2/flax_model.msgpack",
            "size": 2778657095
        },
        {
            "rfilename": "text_encoder_2/model.fp16.safetensors",
            "size": 1389382176
        },
        {
            "rfilename": "text_encoder_2/model.onnx",
            "size": 1041992
        },
        {
            "rfilename": "text_encoder_2/model.onnx_data",
            "size": 2778639360
        },
        {
            "rfilename": "text_encoder_2/model.safetensors",
            "size": 2778702264
        },
        {
            "rfilename": "text_encoder_2/openvino_model.bin",
            "size": 2778640120
        },
        {
            "rfilename": "text_encoder_2/openvino_model.xml",
            "size": 2790191
        },
        {
            "rfilename": "tokenizer/merges.txt",
            "size": 524619
        },
        {
            "rfilename": "tokenizer/special_tokens_map.json",
            "size": 472
        },
        {
            "rfilename": "tokenizer/tokenizer_config.json",
            "size": 737
        },
        {
            "rfilename": "tokenizer/vocab.json",
            "size": 1059962
        },
        {
            "rfilename": "tokenizer_2/merges.txt",
            "size": 524619
        },
        {
            "rfilename": "tokenizer_2/special_tokens_map.json",
            "size": 460
        },
        {
            "rfilename": "tokenizer_2/tokenizer_config.json",
            "size": 725
        },
        {
            "rfilename": "tokenizer_2/vocab.json",
            "size": 1059962
        },
        {
            "rfilename": "unet/config.json",
            "size": 1680
        },
        {
            "rfilename": "unet/diffusion_flax_model.msgpack",
            "size": 10269915611
        },
        {
            "rfilename": "unet/diffusion_pytorch_model.fp16.safetensors",
            "size": 5135149760
        },
        {
            "rfilename": "unet/diffusion_pytorch_model.safetensors",
            "size": 10270077736
        },
        {
            "rfilename": "unet/model.onnx",
            "size": 7293842
        },
        {
            "rfilename": "unet/model.onnx_data",
            "size": 10269854720
        },
        {
            "rfilename": "unet/openvino_model.bin",
            "size": 10269856428
        },
        {
            "rfilename": "unet/openvino_model.xml",
            "size": 22577438
        },
        {
            "rfilename": "vae/config.json",
            "size": 642
        },
        {
            "rfilename": "vae/diffusion_flax_model.msgpack",
            "size": 334623853
        },
        {
            "rfilename": "vae/diffusion_pytorch_model.fp16.safetensors",
            "size": 167335342
        },
        {
            "rfilename": "vae/diffusion_pytorch_model.safetensors",
            "size": 334643268
        },
        {
            "rfilename": "vae_1_0/config.json",
            "size": 607
        },
        {
            "rfilename": "vae_1_0/diffusion_pytorch_model.fp16.safetensors",
            "size": 167335342
        },
        {
            "rfilename": "vae_1_0/diffusion_pytorch_model.safetensors",
            "size": 334643268
        },
        {
            "rfilename": "vae_decoder/config.json",
            "size": 607
        },
        {
            "rfilename": "vae_decoder/model.onnx",
            "size": 198093688
        },
        {
            "rfilename": "vae_decoder/openvino_model.bin",
            "size": 197961232
        },
        {
            "rfilename": "vae_decoder/openvino_model.xml",
            "size": 992181
        },
        {
            "rfilename": "vae_encoder/config.json",
            "size": 607
        },
        {
            "rfilename": "vae_encoder/model.onnx",
            "size": 136775724
        },
        {
            "rfilename": "vae_encoder/openvino_model.bin",
            "size": 136655184
        },
        {
            "rfilename": "vae_encoder/openvino_model.xml",
            "size": 849965
        }
    ],
    "safetensors": null,
    "cardData": {
        "tags": [
            "text-to-image",
            "stable-diffusion"
        ],
        "base_model": null
    }
}